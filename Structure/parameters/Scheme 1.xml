<structure>
	<autoencoders>
        <input>
            <type>Placeholder</type>
            <input_shape>None,61,73,1</input_shape>
            <dtype>float32</dtype>
            <scope>input</scope>
        </input>

        <input>
            <type>Placeholder</type>
            <input_shape></input_shape>
            <dtype>float32</dtype>
            <scope>learning_rate</scope>
        </input>

		<autoencoder>
			<encoder>
				<type>Convolution2D</type>
				<kernel_shape>6,6,1,16</kernel_shape>
				<activation>tanh</activation>
				<strides>1,1,1,1</strides>
				<padding>VALID</padding>
				<scope>conv_1</scope>
				<batch_normalization>True</batch_normalization>
			</encoder>


			<decoder>
				<type>DeConvolution2D</type>
				<kernel_shape>6,6,1,16</kernel_shape>
				<padding>VALID</padding>
				<output_shape>None,61,73,2</output_shape>
				<activation>sigmoid</activation>
				<scope>reconstruction</scope>
			</decoder>
		</autoencoder>

		<autoencoder>
			<encoder>
				<type>MaxPooling</type>
				<kernel_shape>1,2,2,1</kernel_shape>
				<strides>1,2,2,1</strides>
				<padding>VALID</padding>
				<scope>pool_1</scope>
			</encoder>

			<decoder>
				<type>UnPooling</type>
				<kernel_shape>2,2</kernel_shape>
				<scope>unpool_1</scope>
			</decoder>
		</autoencoder>

		<autoencoder>
			<encoder>
				<type>Convolution2D</type>
				<kernel_shape>5,5,16,16</kernel_shape>
				<strides>1,1,1,1</strides>
				<padding>VALID</padding>
				<activation>tanh</activation>
                <batch_normalization>True</batch_normalization>
				<scope>conv_2</scope>
			</encoder>

			<decoder>
				<type>DeConvolution2D</type>
				<kernel_shape>5,5,16,16</kernel_shape>
				<output_shape>pool_1</output_shape>
				<padding>VALID</padding>
				<activation>sigmoid</activation>
				<scope>deconv_2</scope>
			</decoder>
		</autoencoder>

		<autoencoder>
			<encoder>
				<type>MaxPooling</type>
				<kernel_shape>1,2,2,1</kernel_shape>
				<strides>1,2,2,1</strides>
				<padding>VALID</padding>
				<scope>pool_2</scope>
			</encoder>

			<decoder>
				<type>UnPooling</type>
				<kernel_shape>2,2</kernel_shape>
				<scope>unpool_2</scope>
			</decoder>
		</autoencoder>

		<autoencoder>
			<encoder>
				<type>Unfold</type>
				<scope>unfold</scope>
			</encoder>

			<decoder>
				<type>Fold</type>
				<fold_shape>-1,12,15,16</fold_shape>
				<scope>fold</scope>
			</decoder>
		</autoencoder>

		<autoencoder>
			<encoder>
				<type>FullyConnected</type>
				<kernel_shape>2880,500</kernel_shape>
				<activation>tanh</activation>
                <batch_normalization>True</batch_normalization>
				<scope>encode_1</scope>
			</encoder>

			<decoder>
				<type>FullyConnected</type>
				<kernel_shape>500,2880</kernel_shape>
				<activation>sigmoid</activation>
				<scope>decode_1</scope>
			</decoder>
		</autoencoder>

		<autoencoder>
			<encoder>
				<type>FullyConnected</type>
				<kernel_shape>500,61</kernel_shape>
				<activation>tanh</activation>
                <batch_normalization>True</batch_normalization>
				<scope>encoder</scope>
				<input>unfold</input>
			</encoder>

			<decoder>
				<type>FullyConnected</type>
				<kernel_shape>61,500</kernel_shape>
				<activation>sigmoid</activation>
				<scope>decode_2</scope>
				<input>encode</input>
			</decoder>
		</autoencoder>
	</autoencoders>

	<classifier>
        <input>
            <type>Placeholder</type>
            <input_shape>None,61,61,1</input_shape>
            <dtype>float32</dtype>
            <scope>input</scope>
        </input>

        <input>
            <type>Placeholder</type>
            <input_shape>None,2</input_shape>
            <dtype>float32</dtype>
            <scope>output</scope>
        </input>

        <input>
            <type>Placeholder</type>
            <input_shape></input_shape>
            <dtype>float32</dtype>
            <scope>learning_rate</scope>
        </input>

        <layer>
            <type>Convolution2D</type>
            <kernel_shape>7,7,1,32</kernel_shape>
            <activation>tanh</activation>
			<batch_normalization>True</batch_normalization>
            <padding>VALID</padding>
            <scope>conv_1</scope>
            <input>input</input>
        </layer>

        <layer>
            <type>MaxPooling</type>
            <kernel_shape>1,2,2,1</kernel_shape>
            <strides>1,2,2,1</strides>
            <padding>VALID</padding>
            <scope>pool_1</scope>
            <input>conv_1</input>
        </layer>

        <layer>
            <type>Convolution2D</type>
            <kernel_shape>5,5,32,64</kernel_shape>
            <activation>tanh</activation>
            <padding>VALID</padding>
			<batch_normalization>True</batch_normalization>
            <scope>conv_2</scope>
            <input>pool_1</input>
        </layer>

        <layer>
            <type>MaxPooling</type>
            <kernel_shape>1,2,2,1</kernel_shape>
            <strides>1,2,2,1</strides>
            <padding>VALID</padding>
            <scope>pool_2</scope>
            <input>conv_2</input>
        </layer>

        <layer>
            <type>Convolution2D</type>
            <kernel_shape>7,7,64,32</kernel_shape>
            <activation>tanh</activation>
            <padding>VALID</padding>
			<batch_normalization>True</batch_normalization>
            <scope>conv_3</scope>
            <input>pool_2</input>
        </layer>

        <layer>
            <type>MaxPooling</type>
            <kernel_shape>1,2,2,1</kernel_shape>
            <strides>1,2,2,1</strides>
            <padding>VALID</padding>
            <scope>pool_3</scope>
            <input>conv_3</input>
        </layer>

        <layer>
            <type>Unfold</type>
            <scope>unfold</scope>
            <input>pool_3</input>
        </layer>

        <layer>
            <type>FullyConnected</type>
            <kernel_shape>128,32</kernel_shape>
            <activation>sigmoid</activation>
			<batch_normalization>True</batch_normalization>
            <scope>hidden2</scope>
            <input>hidden1</input>
        </layer>

        <layer>
            <type>FullyConnected</type>
            <kernel_shape>32,2</kernel_shape>
            <activation>sigmoid</activation>
            <scope>hidden2</scope>
            <input>hidden1</input>
        </layer>

        <layer>
            <type>Softmax</type>
            <scope>softmax</scope>
            <input>hidden2</input>
        </layer>
	</classifier>
</structure>